{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-13T12:58:17.027858Z","iopub.status.busy":"2023-12-13T12:58:17.027443Z","iopub.status.idle":"2023-12-13T12:58:17.070636Z","shell.execute_reply":"2023-12-13T12:58:17.069335Z","shell.execute_reply.started":"2023-12-13T12:58:17.027825Z"},"trusted":true},"outputs":[],"source":["def character_error_rate(original_text, predicted_text):\n","    # Tokenize the texts into lists of characters\n","    original_chars = list(original_text.lower())\n","    predicted_chars = list(predicted_text.lower())\n","\n","    # Create sets to calculate insertions, deletions, and substitutions\n","    original_set = set(original_chars)\n","    predicted_set = set(predicted_chars)\n","\n","    # Calculate CER\n","    total_chars = len(original_chars)\n","    incorrect_chars = len(original_set.symmetric_difference(predicted_set))\n","\n","    # Avoid division by zero\n","    if total_chars == 0:\n","        return 0.0\n","\n","    cer = (incorrect_chars / total_chars) * 100\n","\n","    return cer\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","cer = character_error_rate(original_text, predicted_text)\n","\n","print(f\"Character Error Rate: {cer}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:17.073600Z","iopub.status.busy":"2023-12-13T12:58:17.072875Z","iopub.status.idle":"2023-12-13T12:58:17.083726Z","shell.execute_reply":"2023-12-13T12:58:17.082942Z","shell.execute_reply.started":"2023-12-13T12:58:17.073506Z"},"trusted":true},"outputs":[],"source":["def character_error_rate_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_errors = 0\n","    total_chars = 0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Tokenize the texts into lists of characters\n","        original_chars = list(original_text.lower())\n","        predicted_chars = list(predicted_text.lower())\n","\n","        # Calculate the number of insertions, deletions, and substitutions\n","        errors = sum(1 for char in original_chars if char not in predicted_chars) + \\\n","                 sum(1 for char in predicted_chars if char not in original_chars)\n","\n","        total_errors += errors\n","        total_chars += max(len(original_chars), len(predicted_chars))\n","\n","    # Avoid division by zero\n","    if total_chars == 0:\n","        return 0.0\n","\n","    cer = (total_errors / total_chars) * 100\n","\n","    return cer\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\"]\n","predicted_texts = [\"This is the predicted text.\"]\n","average_cer = character_error_rate_list(original_texts, predicted_texts)\n","\n","print(f\"Average Character Error Rate: {average_cer}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:17.085941Z","iopub.status.busy":"2023-12-13T12:58:17.085287Z","iopub.status.idle":"2023-12-13T12:58:17.112453Z","shell.execute_reply":"2023-12-13T12:58:17.111215Z","shell.execute_reply.started":"2023-12-13T12:58:17.085908Z"},"trusted":true},"outputs":[],"source":["def levenshtein_distance(original_text, predicted_text):\n","    m = len(original_text)\n","    n = len(predicted_text)\n","\n","    # Initialize a matrix to store distances\n","    distance_matrix = [[0] * (n + 1) for _ in range(m + 1)]\n","\n","    # Fill in the matrix\n","    for i in range(m + 1):\n","        for j in range(n + 1):\n","            if i == 0:\n","                distance_matrix[i][j] = j\n","            elif j == 0:\n","                distance_matrix[i][j] = i\n","            else:\n","                cost = 0 if original_text[i - 1] == predicted_text[j - 1] else 1\n","                distance_matrix[i][j] = min(\n","                    distance_matrix[i - 1][j] + 1,        # Deletion\n","                    distance_matrix[i][j - 1] + 1,        # Insertion\n","                    distance_matrix[i - 1][j - 1] + cost  # Substitution\n","                )\n","\n","    return distance_matrix[m][n]\n","\n","def character_error_rate(original_text, predicted_text):\n","    total_chars = len(original_text)\n","    distance = levenshtein_distance(original_text, predicted_text)\n","    \n","    \n","    print(f\"Levenshtein Distance (Single): {distance}\")\n","    print(f\"Total Characters (Single): {total_chars}\")\n","    \n","    # Avoid division by zero\n","    if total_chars == 0:\n","        return 0.0\n","\n","    cer = (distance / total_chars) * 100\n","\n","    return cer\n","\n","def character_error_rate_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_errors = 0\n","    total_chars = 0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        distance = levenshtein_distance(original_text, predicted_text)\n","        total_chars += max(len(original_text), len(predicted_text))\n","        total_errors += distance\n","\n","    # Avoid division by zero\n","    if total_chars == 0:\n","        return 0.0\n","\n","    cer = (total_errors / total_chars) * 100\n","\n","    return cer\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","\n","cer_single = character_error_rate(original_text, predicted_text)\n","print(f\"Character Error Rate (Single): {cer_single}%\")\n","\n","original_texts = [\"This is the original text.\"]\n","predicted_texts = [\"This is the predicted text.\"]\n","\n","# original_text = [\"kitten is on the wall\"]\n","# predicted_text = [\"sitting is on the car\"]\n","\n","average_cer = character_error_rate_list(original_texts, predicted_texts)\n","print(f\"Average Character Error Rate: {average_cer}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:17.116486Z","iopub.status.busy":"2023-12-13T12:58:17.116142Z","iopub.status.idle":"2023-12-13T12:58:27.503819Z","shell.execute_reply":"2023-12-13T12:58:27.502316Z","shell.execute_reply.started":"2023-12-13T12:58:17.116457Z"},"trusted":true},"outputs":[],"source":["from torchmetrics.text import CharErrorRate\n","original_text = [\"This is the original text.\"]\n","predicted_text = [\"This is the predicted text.\"]\n","cer = CharErrorRate()\n","cer(predicted_text, original_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:27.505834Z","iopub.status.busy":"2023-12-13T12:58:27.505352Z","iopub.status.idle":"2023-12-13T12:58:27.516619Z","shell.execute_reply":"2023-12-13T12:58:27.513959Z","shell.execute_reply.started":"2023-12-13T12:58:27.505801Z"},"trusted":true},"outputs":[],"source":["def word_error_rate(original_text, predicted_text):\n","    # Tokenize the texts into lists of words\n","    original_words = original_text.lower().split()\n","    predicted_words = predicted_text.lower().split()\n","\n","    # Create sets to calculate insertions, deletions, and substitutions\n","    original_set = set(original_words)\n","    predicted_set = set(predicted_words)\n","\n","    # Calculate WER\n","    total_words = len(original_words)\n","    incorrect_words = len(original_set.symmetric_difference(predicted_set))\n","\n","    # Avoid division by zero\n","    if total_words == 0:\n","        return 0.0\n","\n","    wer = (incorrect_words / total_words) * 100\n","\n","    return wer\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","wer = word_error_rate(original_text, predicted_text)\n","\n","print(f\"Word Error Rate: {wer}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:27.519393Z","iopub.status.busy":"2023-12-13T12:58:27.518447Z","iopub.status.idle":"2023-12-13T12:58:27.556367Z","shell.execute_reply":"2023-12-13T12:58:27.554805Z","shell.execute_reply.started":"2023-12-13T12:58:27.519346Z"},"trusted":true},"outputs":[],"source":["def calculate_wer(original_texts, predicted_texts):\n","    total_substitutions = 0\n","    total_deletions = 0\n","    total_insertions = 0\n","    total_words = 0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        ref_words = original_text.split()\n","        hyp_words = predicted_text.split()\n","\n","        substitutions = sum(1 for ref, hyp in zip(ref_words, hyp_words) if ref != hyp)\n","        deletions = len(ref_words) - len(hyp_words)\n","        insertions = len(hyp_words) - len(ref_words)\n","\n","        total_substitutions += substitutions\n","        total_deletions += deletions\n","        total_insertions += insertions\n","        total_words += len(ref_words)\n","\n","    # Avoid division by zero\n","    if total_words == 0:\n","        return 0.0\n","\n","    wer = (total_substitutions + total_deletions + total_insertions) / total_words\n","\n","    return wer\n","\n","average_wer = calculate_wer(original_texts, predicted_texts)\n","\n","print(f\"Average Word Error Rate: {average_wer}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:27.559436Z","iopub.status.busy":"2023-12-13T12:58:27.558656Z","iopub.status.idle":"2023-12-13T12:58:27.574553Z","shell.execute_reply":"2023-12-13T12:58:27.572766Z","shell.execute_reply.started":"2023-12-13T12:58:27.559388Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","def calculate_wer_list(original_texts, predicted_texts):\n","    total_errors = 0\n","    total_words = 0\n","\n","    for original_texts, predicted_texts in zip(original_texts, predicted_texts):\n","        # Split the reference and hypothesis sentences into words\n","        ref_words = original_texts.split()\n","        hyp_words = predicted_texts.split()\n","        # Initialize a matrix with size |ref_words|+1 x |hyp_words|+1\n","        # The extra row and column are for the case when one of the strings is empty\n","        d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n","        # The number of operations for an empty hypothesis to become the reference\n","        # is just the number of words in the reference (i.e., deleting all words)\n","        for i in range(len(ref_words) + 1):\n","            d[i, 0] = i\n","        # The number of operations for an empty reference to become the hypothesis\n","        # is just the number of words in the hypothesis (i.e., inserting all words)\n","        for j in range(len(hyp_words) + 1):\n","            d[0, j] = j\n","        # Iterate over the words in the reference and hypothesis\n","        for i in range(1, len(ref_words) + 1):\n","            for j in range(1, len(hyp_words) + 1):\n","                # If the current words are the same, no operation is needed\n","                # So we just take the previous minimum number of operations\n","                if ref_words[i - 1] == hyp_words[j - 1]:\n","                    d[i, j] = d[i - 1, j - 1]\n","                else:\n","                    # If the words are different, we consider three operations:\n","                    # substitution, insertion, and deletion\n","                    # And we take the minimum of these three possibilities\n","                    substitution = d[i - 1, j - 1] + 1\n","                    insertion = d[i, j - 1] + 1\n","                    deletion = d[i - 1, j] + 1\n","                    d[i, j] = min(substitution, insertion, deletion)\n","        # The minimum number of operations to transform the hypothesis into the reference\n","        # is in the bottom-right cell of the matrix\n","        # We add this to the total errors\n","        total_errors += d[len(ref_words), len(hyp_words)]\n","        total_words += len(ref_words)\n","\n","    # Avoid division by zero\n","    if total_words == 0:\n","        return 0.0\n","\n","    # Calculate the average WER\n","    wer = total_errors / total_words\n","\n","    return wer\n","\n","average_wer = calculate_wer(original_texts, predicted_texts)\n","\n","print(f\"Average Word Error Rate: {average_wer}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:27.576389Z","iopub.status.busy":"2023-12-13T12:58:27.575939Z","iopub.status.idle":"2023-12-13T12:58:29.195757Z","shell.execute_reply":"2023-12-13T12:58:29.194548Z","shell.execute_reply.started":"2023-12-13T12:58:27.576355Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","def calculate_bleu(original_text, predicted_text):\n","    # Tokenize the texts into lists of words\n","    original_tokens = nltk.word_tokenize(original_text.lower())\n","    predicted_tokens = nltk.word_tokenize(predicted_text.lower())\n","\n","    # Calculate BLEU score\n","    bleu_score = sentence_bleu([original_tokens], predicted_tokens)\n","\n","    return bleu_score\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","bleu_score = calculate_bleu(original_text, predicted_text)\n","\n","print(f\"BLEU Score: {bleu_score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.197739Z","iopub.status.busy":"2023-12-13T12:58:29.197392Z","iopub.status.idle":"2023-12-13T12:58:29.208900Z","shell.execute_reply":"2023-12-13T12:58:29.207680Z","shell.execute_reply.started":"2023-12-13T12:58:29.197708Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","def calculate_bleu_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_bleu = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Tokenize the texts into lists of words\n","        original_tokens = nltk.word_tokenize(original_text.lower())\n","        predicted_tokens = nltk.word_tokenize(predicted_text.lower())\n","\n","        # Calculate BLEU score for the current pair of texts\n","        bleu_score = sentence_bleu([original_tokens], predicted_tokens)\n","\n","        total_bleu += bleu_score\n","\n","    # Calculate the average BLEU score across all pairs\n","    average_bleu = total_bleu / len(original_texts)\n","\n","    return average_bleu\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_bleu = calculate_bleu_list(original_texts, predicted_texts)\n","\n","print(f\"Average BLEU Score: {average_bleu}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.214494Z","iopub.status.busy":"2023-12-13T12:58:29.213962Z","iopub.status.idle":"2023-12-13T12:58:29.227905Z","shell.execute_reply":"2023-12-13T12:58:29.226773Z","shell.execute_reply.started":"2023-12-13T12:58:29.214442Z"},"trusted":true},"outputs":[],"source":["def jaccard_similarity(original_text, predicted_text):\n","    # Tokenize the texts into sets of characters\n","    original_set = set(original_text.lower())\n","    predicted_set = set(predicted_text.lower())\n","\n","    # Calculate Jaccard Similarity\n","    intersection_size = len(original_set.intersection(predicted_set))\n","    union_size = len(original_set.union(predicted_set))\n","\n","    # Avoid division by zero\n","    if union_size == 0:\n","        return 0.0\n","\n","    similarity = intersection_size / union_size\n","    return similarity\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","jaccard_score = jaccard_similarity(original_text, predicted_text)\n","\n","print(f\"Jaccard Similarity: {jaccard_score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.230579Z","iopub.status.busy":"2023-12-13T12:58:29.229579Z","iopub.status.idle":"2023-12-13T12:58:29.244430Z","shell.execute_reply":"2023-12-13T12:58:29.243129Z","shell.execute_reply.started":"2023-12-13T12:58:29.230543Z"},"trusted":true},"outputs":[],"source":["def levenshtein_distance(original_text, predicted_text):\n","    m = len(original_text)\n","    n = len(predicted_text)\n","\n","    # Initialize a matrix to store distances\n","    distance_matrix = [[0] * (n + 1) for _ in range(m + 1)]\n","\n","    # Initialize the first row and column\n","    for i in range(m + 1):\n","        distance_matrix[i][0] = i\n","    for j in range(n + 1):\n","        distance_matrix[0][j] = j\n","\n","    # Fill in the matrix\n","    for i in range(1, m + 1):\n","        for j in range(1, n + 1):\n","            cost = 0 if original_text[i - 1] == predicted_text[j - 1] else 1\n","            distance_matrix[i][j] = min(\n","                distance_matrix[i - 1][j] + 1,        # Deletion\n","                distance_matrix[i][j - 1] + 1,        # Insertion\n","                distance_matrix[i - 1][j - 1] + cost  # Substitution\n","            )\n","    \n","    # Calculate Levenshtein Distance\n","    levenshtein_distance = distance_matrix[m][n]\n","\n","    # Calculate the maximum length\n","    max_length = max(m, n)\n","\n","    # Calculate error rate percentage\n","    error_rate_percentage = (levenshtein_distance / max_length) * 100\n","\n","    # The bottom-right cell contains the Levenshtein Distance\n","    return levenshtein_distance,error_rate_percentage\n","\n","# Example usage:\n","original_text = \"kitten is on the wall\"\n","predicted_text = \"sitting is on the car\"\n","distance = levenshtein_distance(original_text, predicted_text)\n","\n","print(f\"Levenshtein Distance: {distance}\")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-14T12:27:17.460922Z","iopub.status.busy":"2023-12-14T12:27:17.460585Z","iopub.status.idle":"2023-12-14T12:27:17.469569Z","shell.execute_reply":"2023-12-14T12:27:17.468810Z","shell.execute_reply.started":"2023-12-14T12:27:17.460895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9574468085106383\n","0.8653846153846154\n","1.0\n","1.0\n","1.0\n","Precision: 1.0\n","Recall: 1.0\n","F1-Score: 1.0\n"]}],"source":["import Levenshtein\n","\n","def text_similarity_evaluation(original_texts, predicted_texts, threshold=0.8):\n","    tp, fp, fn = 0, 0, 0\n","\n","    for label, pred in zip(original_texts, predicted_texts):\n","        similarity_score = 1 - Levenshtein.distance(label, pred) / max(len(label), len(pred))\n","        print(similarity_score)\n","        if similarity_score >= threshold:\n","            tp += 1\n","        else:\n","            fp += 1\n","\n","    fn = len(original_texts) - tp\n","    \n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","    return precision, recall, f1_score\n","\n","# Example usage\n","original_texts = [\"Imagine a vast sheet of paper on which straight\",\n","\"Lines Triangles Squares Pentagons Hexagons and other\",\n","\"figures instead of remaining fixed in their places\",\n","\"move freely about on or in the surface but without\",\n","\"the power of rising above or sinking below it\"]            \n","\n","predicted_texts = [\"Imagine a vast shell of paper on which straight\",\n","\"dines Triangle Squares Pentagons Halagous and older\",\n","\"figures instead of remaining fixed in their places\",\n","\"move freely about on or in the surface but without\",\n","\"the power of rising above or sinking below it\"]\n","\n","precision, recall, f1_score = text_similarity_evaluation(original_texts, predicted_texts, threshold=0.8)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-Score:\", f1_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.246530Z","iopub.status.busy":"2023-12-13T12:58:29.245897Z","iopub.status.idle":"2023-12-13T12:58:29.264458Z","shell.execute_reply":"2023-12-13T12:58:29.263139Z","shell.execute_reply.started":"2023-12-13T12:58:29.246498Z"},"trusted":true},"outputs":[],"source":["def calculate_f1(original_text, predicted_text):\n","    original_words = set(original_text.lower().split())\n","    predicted_words = set(predicted_text.lower().split())\n","\n","    true_positives = len(original_words.intersection(predicted_words))\n","    false_positives = len(predicted_words - original_words)\n","    false_negatives = len(original_words - predicted_words)\n","\n","    precision_denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","    recall_denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","    precision = true_positives / precision_denominator\n","    recall = true_positives / recall_denominator\n","\n","    f1_denominator = precision + recall if precision + recall != 0 else 1\n","    f1_score = 2 * (precision * recall) / f1_denominator\n","\n","    return f1_score\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","f1_score = calculate_f1(original_text, predicted_text)\n","\n","print(f\"F1 Score: {f1_score:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.266374Z","iopub.status.busy":"2023-12-13T12:58:29.265879Z","iopub.status.idle":"2023-12-13T12:58:29.287885Z","shell.execute_reply":"2023-12-13T12:58:29.286888Z","shell.execute_reply.started":"2023-12-13T12:58:29.266340Z"},"trusted":true},"outputs":[],"source":["def calculate_f1_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_f1 = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Tokenize the texts into sets of words\n","        original_words = set(original_text.lower().split())\n","        predicted_words = set(predicted_text.lower().split())\n","\n","        true_positives = len(original_words.intersection(predicted_words))\n","        false_positives = len(predicted_words - original_words)\n","        false_negatives = len(original_words - predicted_words)\n","\n","        precision_denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","        recall_denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","        precision = true_positives / precision_denominator\n","        recall = true_positives / recall_denominator\n","\n","        f1_denominator = precision + recall if precision + recall != 0 else 1\n","        f1_score = 2 * (precision * recall) / f1_denominator\n","\n","        total_f1 += f1_score\n","\n","    # Calculate the average F1 across all pairs\n","    average_f1 = total_f1 / len(original_texts)\n","\n","    return average_f1\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_f1 = calculate_f1_list(original_texts, predicted_texts)\n","\n","print(f\"Average F1 Score: {average_f1:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.289687Z","iopub.status.busy":"2023-12-13T12:58:29.289246Z","iopub.status.idle":"2023-12-13T12:58:29.316826Z","shell.execute_reply":"2023-12-13T12:58:29.315263Z","shell.execute_reply.started":"2023-12-13T12:58:29.289656Z"},"trusted":true},"outputs":[],"source":["def calculate_f1_char(original_text, predicted_text):\n","    original_chars = set(original_text.lower())\n","    predicted_chars = set(predicted_text.lower())\n","\n","    true_positives = len(original_chars.intersection(predicted_chars))\n","    false_positives = len(predicted_chars - original_chars)\n","    false_negatives = len(original_chars - predicted_chars)\n","\n","    precision_denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","    recall_denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","    precision = true_positives / precision_denominator\n","    recall = true_positives / recall_denominator\n","\n","    f1_denominator = precision + recall if precision + recall != 0 else 1\n","    f1_score = 2 * (precision * recall) / f1_denominator\n","\n","    return f1_score\n","\n","def calculate_f1_list_char(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_f1 = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Calculate F1 for the current pair of texts\n","        f1_score = calculate_f1_char(original_text, predicted_text)\n","        total_f1 += f1_score\n","\n","    # Calculate the average F1 across all pairs\n","    average_f1 = total_f1 / len(original_texts)\n","\n","    return average_f1\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_f1_char = calculate_f1_list_char(original_texts, predicted_texts)\n","\n","print(f\"Average F1 Score (Character): {average_f1_char:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.319048Z","iopub.status.busy":"2023-12-13T12:58:29.318408Z","iopub.status.idle":"2023-12-13T12:58:29.342481Z","shell.execute_reply":"2023-12-13T12:58:29.341172Z","shell.execute_reply.started":"2023-12-13T12:58:29.318980Z"},"trusted":true},"outputs":[],"source":["def calculate_precision(original_text, predicted_text):\n","    # Tokenize the texts into sets of words\n","    original_words = set(original_text.lower().split())\n","    predicted_words = set(predicted_text.lower().split())\n","\n","    # Calculate true positives (intersection of sets)\n","    true_positives = len(original_words.intersection(predicted_words))\n","\n","    # Calculate false positives\n","    false_positives = len(predicted_words - original_words)\n","\n","    # Avoid division by zero\n","    denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","\n","    # Calculate precision\n","    precision = true_positives / denominator\n","\n","    return precision\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","precision = calculate_precision(original_text, predicted_text)\n","\n","print(f\"Precision: {precision:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.344559Z","iopub.status.busy":"2023-12-13T12:58:29.344104Z","iopub.status.idle":"2023-12-13T12:58:29.364093Z","shell.execute_reply":"2023-12-13T12:58:29.362755Z","shell.execute_reply.started":"2023-12-13T12:58:29.344521Z"},"trusted":true},"outputs":[],"source":["def calculate_precision_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_precision = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Tokenize the texts into sets of words\n","        original_words = set(original_text.lower().split())\n","        predicted_words = set(predicted_text.lower().split())\n","\n","        # Calculate true positives (intersection of sets)\n","        true_positives = len(original_words.intersection(predicted_words))\n","\n","        # Calculate false positives\n","        false_positives = len(predicted_words - original_words)\n","\n","        # Avoid division by zero\n","        denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","\n","        # Calculate precision for the current pair of texts\n","        precision = true_positives / denominator\n","        total_precision += precision\n","\n","    # Calculate the average precision across all pairs\n","    average_precision = total_precision / len(original_texts)\n","\n","    return average_precision\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_precision = calculate_precision_list(original_texts, predicted_texts)\n","\n","print(f\"Average Precision: {average_precision:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.366499Z","iopub.status.busy":"2023-12-13T12:58:29.365684Z","iopub.status.idle":"2023-12-13T12:58:29.388055Z","shell.execute_reply":"2023-12-13T12:58:29.387094Z","shell.execute_reply.started":"2023-12-13T12:58:29.366457Z"},"trusted":true},"outputs":[],"source":["def calculate_precision_char(original_text, predicted_text):\n","    # Tokenize the texts into sets of characters\n","    original_chars = set(original_text.lower())\n","    predicted_chars = set(predicted_text.lower())\n","\n","    # Calculate true positives (intersection of sets)\n","    true_positives = len(original_chars.intersection(predicted_chars))\n","\n","    # Calculate false positives\n","    false_positives = len(predicted_chars - original_chars)\n","\n","    # Avoid division by zero\n","    denominator = true_positives + false_positives if true_positives + false_positives != 0 else 1\n","\n","    # Calculate precision\n","    precision = true_positives / denominator\n","\n","    return precision\n","\n","def calculate_precision_list_char(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_precision = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Calculate precision for the current pair of texts\n","        precision = calculate_precision_char(original_text, predicted_text)\n","        total_precision += precision\n","\n","    # Calculate the average precision across all pairs\n","    average_precision = total_precision / len(original_texts)\n","\n","    return average_precision\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_precision_char = calculate_precision_list_char(original_texts, predicted_texts)\n","\n","print(f\"Average Precision (Character): {average_precision_char:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.390291Z","iopub.status.busy":"2023-12-13T12:58:29.389950Z","iopub.status.idle":"2023-12-13T12:58:29.414986Z","shell.execute_reply":"2023-12-13T12:58:29.413962Z","shell.execute_reply.started":"2023-12-13T12:58:29.390262Z"},"trusted":true},"outputs":[],"source":["def calculate_recall(original_text, predicted_text):\n","    # Tokenize the texts into sets of words\n","    original_words = set(original_text.lower().split())\n","    predicted_words = set(predicted_text.lower().split())\n","\n","    # Calculate true positives (intersection of sets)\n","    true_positives = len(original_words.intersection(predicted_words))\n","\n","    # Calculate false negatives\n","    false_negatives = len(original_words - predicted_words)\n","\n","    # Avoid division by zero\n","    denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","    # Calculate recall\n","    recall = true_positives / denominator\n","\n","    return recall\n","\n","# Example usage:\n","original_text = \"This is the original text.\"\n","predicted_text = \"This is the predicted text.\"\n","recall = calculate_recall(original_text, predicted_text)\n","\n","print(f\"Recall: {recall:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.416981Z","iopub.status.busy":"2023-12-13T12:58:29.416146Z","iopub.status.idle":"2023-12-13T12:58:29.439288Z","shell.execute_reply":"2023-12-13T12:58:29.437986Z","shell.execute_reply.started":"2023-12-13T12:58:29.416950Z"},"trusted":true},"outputs":[],"source":["def calculate_recall_list(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_recall = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Tokenize the texts into sets of words\n","        original_words = set(original_text.lower().split())\n","        predicted_words = set(predicted_text.lower().split())\n","\n","        # Calculate true positives (intersection of sets)\n","        true_positives = len(original_words.intersection(predicted_words))\n","\n","        # Calculate false negatives\n","        false_negatives = len(original_words - predicted_words)\n","\n","        # Avoid division by zero\n","        denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","        # Calculate recall for the current pair of texts\n","        recall = true_positives / denominator\n","        total_recall += recall\n","\n","    # Calculate the average recall across all pairs\n","    average_recall = total_recall / len(original_texts)\n","\n","    return average_recall\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_recall = calculate_recall_list(original_texts, predicted_texts)\n","\n","print(f\"Average Recall: {average_recall:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-13T12:58:29.441598Z","iopub.status.busy":"2023-12-13T12:58:29.440533Z","iopub.status.idle":"2023-12-13T12:58:29.465423Z","shell.execute_reply":"2023-12-13T12:58:29.464154Z","shell.execute_reply.started":"2023-12-13T12:58:29.441562Z"},"trusted":true},"outputs":[],"source":["def calculate_recall_char(original_text, predicted_text):\n","    # Tokenize the texts into sets of characters\n","    original_chars = set(original_text.lower())\n","    predicted_chars = set(predicted_text.lower())\n","\n","    # Calculate true positives (intersection of sets)\n","    true_positives = len(original_chars.intersection(predicted_chars))\n","\n","    # Calculate false negatives\n","    false_negatives = len(original_chars - predicted_chars)\n","\n","    # Avoid division by zero\n","    denominator = true_positives + false_negatives if true_positives + false_negatives != 0 else 1\n","\n","    # Calculate recall\n","    recall = true_positives / denominator\n","\n","    return recall\n","\n","def calculate_recall_list_char(original_texts, predicted_texts):\n","    # Ensure the input lists have the same length\n","    if len(original_texts) != len(predicted_texts):\n","        raise ValueError(\"Input lists must have the same length.\")\n","\n","    total_recall = 0.0\n","\n","    for original_text, predicted_text in zip(original_texts, predicted_texts):\n","        # Calculate recall for the current pair of texts\n","        recall = calculate_recall_char(original_text, predicted_text)\n","        total_recall += recall\n","\n","    # Calculate the average recall across all pairs\n","    average_recall = total_recall / len(original_texts)\n","\n","    return average_recall\n","\n","# Example usage:\n","original_texts = [\"This is the original text.\", \"Another example.\"]\n","predicted_texts = [\"This is the predicted text.\", \"Different example.\"]\n","average_recall_char = calculate_recall_list_char(original_texts, predicted_texts)\n","\n","print(f\"Average Recall (Character): {average_recall_char:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T20:11:52.135842Z","iopub.status.busy":"2023-12-05T20:11:52.135414Z","iopub.status.idle":"2023-12-05T20:11:52.702533Z","shell.execute_reply":"2023-12-05T20:11:52.701221Z","shell.execute_reply.started":"2023-12-05T20:11:52.135808Z"},"trusted":true},"outputs":[],"source":["from evaluate import load\n","cer = load(\"cer\")\n","original_text = [\"This is the original text.\"]\n","predicted_text = [\"This is the predicted text.\"]\n","cer_score = cer.compute(predictions=predicted_text, references=original_text)\n","print(cer_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-05T20:36:13.852759Z","iopub.status.busy":"2023-12-05T20:36:13.852217Z","iopub.status.idle":"2023-12-05T20:36:14.541247Z","shell.execute_reply":"2023-12-05T20:36:14.540360Z","shell.execute_reply.started":"2023-12-05T20:36:13.852716Z"},"trusted":true},"outputs":[],"source":["from evaluate import load\n","wer = load(\"wer\")\n","predictions = [\"this is the prediction\", \"there is an other sample\"]\n","references = [\"this is the reference\", \"there is another one\"]\n","wer_score = wer.compute(predictions=predictions, references=references)\n","print(wer_score)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4099982,"sourceId":7110729,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
