{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7261471,"sourceType":"datasetVersion","datasetId":4208408}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T19:55:53.301828Z","iopub.execute_input":"2023-12-23T19:55:53.302349Z","iopub.status.idle":"2023-12-23T19:55:53.313597Z","shell.execute_reply.started":"2023-12-23T19:55:53.302308Z","shell.execute_reply":"2023-12-23T19:55:53.312303Z"},"trusted":true},"execution_count":193,"outputs":[{"name":"stdout","text":"/kaggle/input/auto-grading-data/Traing_Data_analysis.xlsx\n/kaggle/input/auto-grading-data/Traing_Data_614.xlsx\n/kaggle/input/auto-grading-data/Traing_Data_translated.xlsx\n/kaggle/input/auto-grading-data/Test_Dataset.xlsx\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install spacy  \n!pip install -U sentence-transformers\n!python -m spacy download en_core_web_md\nimport pandas as pd\nimport numpy as np\nimport gensim\nimport torch\nimport spacy\nimport fasttext.util\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom scipy.sparse import vstack","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:55:53.316570Z","iopub.execute_input":"2023-12-23T19:55:53.317507Z","iopub.status.idle":"2023-12-23T19:56:37.004532Z","shell.execute_reply.started":"2023-12-23T19:55:53.317454Z","shell.execute_reply":"2023-12-23T19:56:37.003065Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.1)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.1.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nCollecting en-core-web-md==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-md==3.7.1) (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.1)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.10.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.1.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.24.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = pd.read_excel(\"/kaggle/input/auto-grading-data/Test_Dataset.xlsx\")\ntrain_data_644= pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_614.xlsx\")\ntrain_data_analysis = pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_analysis.xlsx\")\ntrain_data_translated = pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_translated.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:56:37.008086Z","iopub.execute_input":"2023-12-23T19:56:37.009172Z","iopub.status.idle":"2023-12-23T19:56:37.881774Z","shell.execute_reply.started":"2023-12-23T19:56:37.009114Z","shell.execute_reply":"2023-12-23T19:56:37.880226Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"import gensim.downloader as api\n# Load Word2Vec model (pre-trained model available in gensim)\nword2vec_model = api.load(\"word2vec-google-news-300\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:56:37.883497Z","iopub.execute_input":"2023-12-23T19:56:37.883836Z","iopub.status.idle":"2023-12-23T19:57:40.348182Z","shell.execute_reply.started":"2023-12-23T19:56:37.883806Z","shell.execute_reply":"2023-12-23T19:57:40.346926Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"# Load spaCy with GloVe vectors\nnlp = spacy.load(\"en_core_web_md\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:40.350802Z","iopub.execute_input":"2023-12-23T19:57:40.351301Z","iopub.status.idle":"2023-12-23T19:57:42.861755Z","shell.execute_reply.started":"2023-12-23T19:57:40.351251Z","shell.execute_reply":"2023-12-23T19:57:42.860365Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(model, text):\n    words = text.split()  # Split the text into individual words\n    word_embeddings = []\n    for word in words:\n        if word in model:  # Check if the word is in the Word2Vec vocabulary\n            word_embeddings.append(model[word])  # Retrieve the word embedding\n        else:\n            # Handle out-of-vocabulary words if needed\n            pass  # For example, you might skip the word or use a default embedding\n    \n    if word_embeddings:\n        # Calculate the average of word embeddings or apply other aggregation methods\n        sentence_embedding = np.mean(word_embeddings, axis=0)  # Calculate the mean along the axis\n\n        return sentence_embedding  # Return the sentence-level embedding\n    else:\n        return np.zeros(model.vector_size)  # Return zero vector if no embeddings were found\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.863205Z","iopub.execute_input":"2023-12-23T19:57:42.863601Z","iopub.status.idle":"2023-12-23T19:57:42.871354Z","shell.execute_reply.started":"2023-12-23T19:57:42.863566Z","shell.execute_reply":"2023-12-23T19:57:42.870036Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"print(test_data.columns)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.872755Z","iopub.execute_input":"2023-12-23T19:57:42.873120Z","iopub.status.idle":"2023-12-23T19:57:42.885352Z","shell.execute_reply.started":"2023-12-23T19:57:42.873088Z","shell.execute_reply":"2023-12-23T19:57:42.884152Z"},"trusted":true},"execution_count":199,"outputs":[{"name":"stdout","text":"Index(['question', 'model_answer', 'student_answer', 'grade', 'source', 'ID'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"def Gradanizer(num, grade_mode=\"Fair\"):\n    \"\"\"\n    This function take the garde form 0 to 1 and output that garde in form 0 to 5\n\n    parameters\n    num: the garde in form 0 to 1\n    grade_mode: how fair you want to model to be [fair: the exact transformation with out any lose ranges, easy: more skewed into higher grades more \n    common, lose_ends: more skewed into higher grades and lower grades]\n    \"\"\"\n    def get_region_value_f(number):    \n        intervals = [\n        (-10, 0.4545), (0.4545, 0.9091), (0.9091, 1.3636),\n        (1.3636, 1.8182), (1.8182, 2.2727), (2.2727, 2.7273),\n        (2.7273, 3.1818), (3.1818, 3.6364), (3.6364, 4.0909),\n        (4.0909, 4.5455), (4.5455, 6)]\n        values=[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5]\n        for i, (start, end) in enumerate(intervals):\n            if start <= number < end:\n                return values[i]\n        \n    def get_region_value_e(number):    \n        intervals = [\n        (-10, 0.4545), (0.4545, 0.9091), (0.9091, 1.3636),\n        (1.3636, 1.8182), (1.8182, 2.2727), (2.2727, 2.7273),\n        (2.7273, 3.1818), (3.1818, 3.6364)]\n        values=[0,0.5,1,1.5,2,2.5,3,3.5]\n        for i, (start, end) in enumerate(intervals):\n            if start <= number < end:\n                return values[i]\n    def get_region_value_l(number):    \n        intervals = [\n        (1.0000, 1.3571), (1.3571, 1.7143), (1.7143, 2.0714),\n        (2.0714, 2.4286), (2.4286, 2.7857), (2.7857, 3.1429),\n        (3.1429, 3.5000)]\n        values=[0.5,1,1.5,2,2.5,3,3.5]\n        for i, (start, end) in enumerate(intervals):\n            if start <= number < end:\n                return values[i]\n\n    if (grade_mode == \"fair\"):\n        num_f=num*5\n        return get_region_value_f(num_f)\n    elif (grade_mode == \"easy\"):\n        if (num >=0.85):\n            return 5\n        elif ( 0.85>num>=0.8):\n            return 4.5\n        elif ( 0.8>num>=0.7):\n            return 4\n        else:\n            num_e = num*5\n            return get_region_value_e(num_e)\n    elif (grade_mode == \"lose_ends\"):\n        if (num >=0.85):\n            return 5\n        elif ( 0.85>num>=0.8):\n            return 4.5\n        elif ( 0.8>num>=0.7):\n            return 4\n        elif (0.2>=num):\n            return 0\n        else:\n            num_l = num*5\n            return get_region_value_l(num_l)\n    else:\n        print(\"not a valid mode \")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.887296Z","iopub.execute_input":"2023-12-23T19:57:42.887664Z","iopub.status.idle":"2023-12-23T19:57:42.903849Z","shell.execute_reply.started":"2023-12-23T19:57:42.887631Z","shell.execute_reply":"2023-12-23T19:57:42.902636Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import util","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.905783Z","iopub.execute_input":"2023-12-23T19:57:42.906326Z","iopub.status.idle":"2023-12-23T19:57:42.920359Z","shell.execute_reply.started":"2023-12-23T19:57:42.906253Z","shell.execute_reply":"2023-12-23T19:57:42.919081Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import spearmanr\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.922341Z","iopub.execute_input":"2023-12-23T19:57:42.922894Z","iopub.status.idle":"2023-12-23T19:57:42.932030Z","shell.execute_reply.started":"2023-12-23T19:57:42.922848Z","shell.execute_reply":"2023-12-23T19:57:42.930980Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"def Evaluation(embeddings_1=None, embeddings_2=None,test_data=None,mode=\"easy\"):\n    \"\"\"\n    this function takes two lists of embeddings in the form of torch tensor or list or df column one for the student answer and other for model answer\n    or any two sentences if this function used in any other code and the test data frame and the mode of Gradazier and output MAE % and r_squared and \n    correlation_coefficient\n\n    parameters\n    embeddings_1:list or tensor or df column that hold the sentence embeddings (student answer embeddings)\n    embeddings_2:list or tensor or df column that hold the sentence embeddings (model answer embeddings)\n    data: the test data frame\n    mode: the mode of which gradazier is used [\"fair\", \"easy\", \"lose_ends\"]\n    \"\"\"\n    from sentence_transformers import util\n    if (len(embeddings_1) != len(embeddings_2)):\n        print(\"embeddings_1 and embeddings_2 are not the same length\")\n        return None\n    elif (mode not in [\"easy\",\"lose_ends\",\"fair\"]):\n        print(\"not valid mode\")\n        return None\n    else:\n        predicted = []\n        for i in range(len(embeddings_1)):\n            predicted.append(Gradanizer(util.cos_sim(embeddings_1[i], embeddings_2[i]),mode))\n        transformed_grade=[]\n        for i in range(len(embeddings_1)):\n            transformed_grade.append(Gradanizer(test_data[\"grade\"][i],mode))\n            #transformed_grade.append(test_data[\"grade\"][i]*5)\n        arr_predicted =np.array(predicted)\n        arr_grade=np.array(transformed_grade)\n        MAE = (1-((np.sum(np.abs(arr_predicted-arr_grade))/len(embeddings_1))/5))*100\n        correlation_coefficient, p_value = spearmanr(arr_grade, arr_predicted)\n        r_squared = r2_score(arr_grade, arr_predicted)\n        dif =arr_predicted-arr_grade\n        hits_precentage= (np.count_nonzero(dif == 0)/len(embeddings_1))\n        return MAE,correlation_coefficient,r_squared\n        #if you want the hit precentage tag the above and untag the blew\n        #return MAE,correlation_coefficient,hits_precentage\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.937558Z","iopub.execute_input":"2023-12-23T19:57:42.937967Z","iopub.status.idle":"2023-12-23T19:57:42.949592Z","shell.execute_reply.started":"2023-12-23T19:57:42.937932Z","shell.execute_reply":"2023-12-23T19:57:42.948048Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"# Get embeddings for train and test data using different models\ntrain_word2vec = test_data['student_answer'].apply(lambda x: get_embeddings(word2vec_model, x))\ntest_word2vec = test_data['model_answer'].apply(lambda x: get_embeddings(word2vec_model, x))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:42.950959Z","iopub.execute_input":"2023-12-23T19:57:42.951326Z","iopub.status.idle":"2023-12-23T19:57:43.128172Z","shell.execute_reply.started":"2023-12-23T19:57:42.951290Z","shell.execute_reply":"2023-12-23T19:57:43.126766Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"train_word2vec[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.129770Z","iopub.execute_input":"2023-12-23T19:57:43.130142Z","iopub.status.idle":"2023-12-23T19:57:43.144340Z","shell.execute_reply.started":"2023-12-23T19:57:43.130109Z","shell.execute_reply":"2023-12-23T19:57:43.142941Z"},"trusted":true},"execution_count":205,"outputs":[{"execution_count":205,"output_type":"execute_result","data":{"text/plain":"0    [0.038584497, -0.017718472, 0.053652238, 0.100...\n1    [-0.0021623883, -0.0023314613, 0.052162714, 0....\n2    [0.013964201, 0.008574185, 0.01831376, 0.06740...\n3    [-0.009379069, 0.008200905, 0.059607305, 0.096...\n4    [0.029686783, -0.0011798522, 0.0065001543, 0.0...\nName: student_answer, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train_word2vec= torch.tensor(train_word2vec)\ntrain_word2vec[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.146097Z","iopub.execute_input":"2023-12-23T19:57:43.146501Z","iopub.status.idle":"2023-12-23T19:57:43.213886Z","shell.execute_reply.started":"2023-12-23T19:57:43.146464Z","shell.execute_reply":"2023-12-23T19:57:43.212565Z"},"trusted":true},"execution_count":206,"outputs":[{"execution_count":206,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0386, -0.0177,  0.0537,  ..., -0.0176,  0.0411,  0.0087],\n        [-0.0022, -0.0023,  0.0522,  ..., -0.0582,  0.0067,  0.0026],\n        [ 0.0140,  0.0086,  0.0183,  ..., -0.0259, -0.0333,  0.0174],\n        [-0.0094,  0.0082,  0.0596,  ..., -0.0354,  0.0174, -0.0468],\n        [ 0.0297, -0.0012,  0.0065,  ..., -0.0396,  0.0045, -0.0050]],\n       dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"test_word2vec= torch.tensor(test_word2vec)\ntest_word2vec[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.216778Z","iopub.execute_input":"2023-12-23T19:57:43.217168Z","iopub.status.idle":"2023-12-23T19:57:43.279800Z","shell.execute_reply.started":"2023-12-23T19:57:43.217130Z","shell.execute_reply":"2023-12-23T19:57:43.278347Z"},"trusted":true},"execution_count":207,"outputs":[{"execution_count":207,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.0603, -0.0067,  0.0547,  ..., -0.0294,  0.0533, -0.0027],\n        [-0.0121, -0.0123,  0.0270,  ..., -0.0526, -0.0025,  0.0232],\n        [ 0.0164,  0.0048, -0.0057,  ..., -0.0028,  0.0467, -0.0071],\n        [ 0.0603, -0.0067,  0.0547,  ..., -0.0294,  0.0533, -0.0027],\n        [-0.0091,  0.0118,  0.0255,  ..., -0.0364, -0.0146, -0.0007]],\n       dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.281755Z","iopub.execute_input":"2023-12-23T19:57:43.282137Z","iopub.status.idle":"2023-12-23T19:57:43.458797Z","shell.execute_reply.started":"2023-12-23T19:57:43.282104Z","shell.execute_reply":"2023-12-23T19:57:43.457355Z"},"trusted":true},"execution_count":208,"outputs":[{"name":"stdout","text":"75.67338282078472 0.20310990847400123 -0.2531905664319225\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"easy\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.460328Z","iopub.execute_input":"2023-12-23T19:57:43.460681Z","iopub.status.idle":"2023-12-23T19:57:43.590066Z","shell.execute_reply.started":"2023-12-23T19:57:43.460651Z","shell.execute_reply":"2023-12-23T19:57:43.588626Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stdout","text":"74.60233297985154 0.21395528365860808 -0.26623965555920215\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"lose_ends\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.591527Z","iopub.execute_input":"2023-12-23T19:57:43.591998Z","iopub.status.idle":"2023-12-23T19:57:43.725508Z","shell.execute_reply.started":"2023-12-23T19:57:43.591961Z","shell.execute_reply":"2023-12-23T19:57:43.723399Z"},"trusted":true},"execution_count":210,"outputs":[{"name":"stdout","text":"71.89819724284199 0.2121318116148784 -0.24400963653160956\n","output_type":"stream"}]},{"cell_type":"code","source":"train_glove = np.array([nlp(text).vector for text in test_data['student_answer']])\ntest_glove = np.array([nlp(text).vector for text in test_data['model_answer']])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:57:43.727409Z","iopub.execute_input":"2023-12-23T19:57:43.727897Z","iopub.status.idle":"2023-12-23T19:58:11.018560Z","shell.execute_reply.started":"2023-12-23T19:57:43.727856Z","shell.execute_reply":"2023-12-23T19:58:11.016194Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"train_glove= torch.tensor(train_glove)\ntest_glove= torch.tensor(test_glove)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.021438Z","iopub.execute_input":"2023-12-23T19:58:11.023088Z","iopub.status.idle":"2023-12-23T19:58:11.030874Z","shell.execute_reply.started":"2023-12-23T19:58:11.023028Z","shell.execute_reply":"2023-12-23T19:58:11.029656Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.032481Z","iopub.execute_input":"2023-12-23T19:58:11.033609Z","iopub.status.idle":"2023-12-23T19:58:11.274176Z","shell.execute_reply.started":"2023-12-23T19:58:11.033568Z","shell.execute_reply":"2023-12-23T19:58:11.273185Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"73.42523860021208 0.06520601135437996 -0.5530007747644257\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"easy\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.275399Z","iopub.execute_input":"2023-12-23T19:58:11.276179Z","iopub.status.idle":"2023-12-23T19:58:11.401870Z","shell.execute_reply.started":"2023-12-23T19:58:11.276143Z","shell.execute_reply":"2023-12-23T19:58:11.399860Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"73.90243902439025 0.04361425359018988 -0.5487960826142768\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"lose_ends\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.403787Z","iopub.execute_input":"2023-12-23T19:58:11.404204Z","iopub.status.idle":"2023-12-23T19:58:11.520972Z","shell.execute_reply.started":"2023-12-23T19:58:11.404167Z","shell.execute_reply":"2023-12-23T19:58:11.520095Z"},"trusted":true},"execution_count":215,"outputs":[{"name":"stdout","text":"71.62248144220572 0.0418207984264587 -0.5161487988798423\n","output_type":"stream"}]},{"cell_type":"code","source":"#fasttext.util.download_model('en', if_exists='ignore')  # Uncomment if you want to download the FastText model\n#fasttext_model = fasttext.load_model('cc.en.300.bin')  # Load your FastText model (change the path if needed)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.522408Z","iopub.execute_input":"2023-12-23T19:58:11.522949Z","iopub.status.idle":"2023-12-23T19:58:11.528112Z","shell.execute_reply.started":"2023-12-23T19:58:11.522916Z","shell.execute_reply":"2023-12-23T19:58:11.526548Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"code","source":"\n#train_fasttext = np.array([fasttext_model.get_sentence_vector(text) for text in test_data['student_answer']])\n#test_fasttext = np.array([fasttext_model.get_sentence_vector(text) for text in test_data['model_answer']])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.530157Z","iopub.execute_input":"2023-12-23T19:58:11.530812Z","iopub.status.idle":"2023-12-23T19:58:11.539863Z","shell.execute_reply.started":"2023-12-23T19:58:11.530762Z","shell.execute_reply":"2023-12-23T19:58:11.538395Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"#test_fasttext= torch.tensor(test_fasttext)\n#train_fasttext= torch.tensor(train_fasttext)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.541735Z","iopub.execute_input":"2023-12-23T19:58:11.542118Z","iopub.status.idle":"2023-12-23T19:58:11.551956Z","shell.execute_reply.started":"2023-12-23T19:58:11.542069Z","shell.execute_reply":"2023-12-23T19:58:11.550348Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"#!pip install conceptnet\n\n#from conceptnet.nodes import standardized_concept_uri\n#from conceptnet.vectors.query import VectorSpaceWrapper","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.553718Z","iopub.execute_input":"2023-12-23T19:58:11.554095Z","iopub.status.idle":"2023-12-23T19:58:11.563011Z","shell.execute_reply.started":"2023-12-23T19:58:11.554062Z","shell.execute_reply":"2023-12-23T19:58:11.561649Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"def get_embedding_matrix(column_data, vectorizer, lsa_model):\n    # Transform the input column data using the provided TF-IDF vectorizer\n    tfidf_matrix_column = vectorizer.transform(column_data)\n\n    # Obtain the embedding matrix using the provided LSA model\n    embedding_matrix_column = lsa_model.transform(tfidf_matrix_column)\n    \n    return embedding_matrix_column","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.564820Z","iopub.execute_input":"2023-12-23T19:58:11.565233Z","iopub.status.idle":"2023-12-23T19:58:11.576812Z","shell.execute_reply.started":"2023-12-23T19:58:11.565193Z","shell.execute_reply":"2023-12-23T19:58:11.575749Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"code","source":"# Train the initial LSA model on the first dataset\ninitial_text_data = train_data_analysis['student_answer'].tolist() + train_data_analysis['model_answer'].tolist()\ninitial_tfidf_matrix = TfidfVectorizer().fit_transform(initial_text_data)\ninitial_lsa_model = TruncatedSVD(n_components=11).fit(initial_tfidf_matrix)\n\n# Store the initial LSA model and TF-IDF matrix\noverall_embedding_matrix = initial_lsa_model.transform(initial_tfidf_matrix)\noverall_tfidf_matrix = initial_tfidf_matrix\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:11.584689Z","iopub.execute_input":"2023-12-23T19:58:11.585869Z","iopub.status.idle":"2023-12-23T19:58:11.726606Z","shell.execute_reply.started":"2023-12-23T19:58:11.585758Z","shell.execute_reply":"2023-12-23T19:58:11.725380Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers = train_data_analysis['student_answer'].tolist() + train_data_analysis['model_answer'].tolist()\n\n# Create a TF-IDF vectorizer\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(all_answers)\n\n# Perform Singular Value Decomposition (LSA)\nnum_dimensions = 11  # Choose the number of dimensions for the embeddings\nlsa = TruncatedSVD(n_components=num_dimensions)\nembedding_matrix = lsa.fit_transform(tfidf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:29.994849Z","iopub.execute_input":"2023-12-23T20:01:29.995614Z","iopub.status.idle":"2023-12-23T20:01:30.126689Z","shell.execute_reply.started":"2023-12-23T20:01:29.995574Z","shell.execute_reply":"2023-12-23T20:01:30.125333Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n\ntfidf_matrix = vectorizer.transform(all_answers2)\n\nembedding_matrix = lsa.transform(tfidf_matrix)\n\n# Separate embeddings for student and model answers\nstudent_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\nmodel_embeddings2 = embedding_matrix[len(test_data['student_answer']):]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:33.894463Z","iopub.execute_input":"2023-12-23T20:01:33.894910Z","iopub.status.idle":"2023-12-23T20:01:33.952802Z","shell.execute_reply.started":"2023-12-23T20:01:33.894875Z","shell.execute_reply":"2023-12-23T20:01:33.951608Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:35.124085Z","iopub.execute_input":"2023-12-23T20:01:35.124524Z","iopub.status.idle":"2023-12-23T20:01:35.341950Z","shell.execute_reply.started":"2023-12-23T20:01:35.124487Z","shell.execute_reply":"2023-12-23T20:01:35.340804Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stdout","text":"70.95440084835631 0.09677187203405786 -1.05425016067396\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"easy\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:36.404566Z","iopub.execute_input":"2023-12-23T20:01:36.405068Z","iopub.status.idle":"2023-12-23T20:01:36.510837Z","shell.execute_reply.started":"2023-12-23T20:01:36.405025Z","shell.execute_reply":"2023-12-23T20:01:36.509583Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stdout","text":"73.71155885471899 0.09314136286388634 -0.7897280793406143\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"lose_ends\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:37.596254Z","iopub.execute_input":"2023-12-23T20:01:37.596721Z","iopub.status.idle":"2023-12-23T20:01:37.695102Z","shell.execute_reply.started":"2023-12-23T20:01:37.596683Z","shell.execute_reply":"2023-12-23T20:01:37.693917Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"71.5694591728526 0.09011019129467626 -0.7251231308460437\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers = train_data_644['student_answer'].tolist() + train_data_644['model_answer'].tolist()\n\n\ntfidf_matrix = vectorizer.fit_transform(all_answers)\n\nembedding_matrix = lsa.fit(tfidf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:01:52.169520Z","iopub.execute_input":"2023-12-23T20:01:52.169927Z","iopub.status.idle":"2023-12-23T20:01:52.237133Z","shell.execute_reply.started":"2023-12-23T20:01:52.169894Z","shell.execute_reply":"2023-12-23T20:01:52.235577Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n\ntfidf_matrix = vectorizer.transform(all_answers2)\n\nembedding_matrix = lsa.transform(tfidf_matrix)\n\n# Separate embeddings for student and model answers\nstudent_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\nmodel_embeddings2 = embedding_matrix[len(test_data['student_answer']):]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:02:05.367224Z","iopub.execute_input":"2023-12-23T20:02:05.367699Z","iopub.status.idle":"2023-12-23T20:02:05.421104Z","shell.execute_reply.started":"2023-12-23T20:02:05.367659Z","shell.execute_reply":"2023-12-23T20:02:05.419919Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:02:18.609740Z","iopub.execute_input":"2023-12-23T20:02:18.610450Z","iopub.status.idle":"2023-12-23T20:02:18.830658Z","shell.execute_reply.started":"2023-12-23T20:02:18.610409Z","shell.execute_reply":"2023-12-23T20:02:18.829477Z"},"trusted":true},"execution_count":248,"outputs":[{"name":"stdout","text":"70.53022269353129 0.07340128025859846 -1.1079314871435217\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers = train_data_translated['student_answer'].tolist() + train_data_translated['model_answer'].tolist()\n\n\ntfidf_matrix = vectorizer.fit_transform(all_answers)\n\nembedding_matrix = lsa.fit(tfidf_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:02:49.366936Z","iopub.execute_input":"2023-12-23T20:02:49.367706Z","iopub.status.idle":"2023-12-23T20:02:49.534620Z","shell.execute_reply.started":"2023-12-23T20:02:49.367662Z","shell.execute_reply":"2023-12-23T20:02:49.533427Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"# Combine student and model answers\nall_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n\ntfidf_matrix = vectorizer.transform(all_answers2)\n\nembedding_matrix = lsa.transform(tfidf_matrix)\n\n# Separate embeddings for student and model answers\nstudent_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\nmodel_embeddings2 = embedding_matrix[len(test_data['student_answer']):]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:03:16.756953Z","iopub.execute_input":"2023-12-23T20:03:16.757538Z","iopub.status.idle":"2023-12-23T20:03:16.811363Z","shell.execute_reply.started":"2023-12-23T20:03:16.757480Z","shell.execute_reply":"2023-12-23T20:03:16.810275Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:03:25.790208Z","iopub.execute_input":"2023-12-23T20:03:25.791112Z","iopub.status.idle":"2023-12-23T20:03:26.065493Z","shell.execute_reply.started":"2023-12-23T20:03:25.791059Z","shell.execute_reply":"2023-12-23T20:03:26.064330Z"},"trusted":true},"execution_count":251,"outputs":[{"name":"stdout","text":"70.6574761399788 0.01756348328179278 -1.0918270892026531\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import Doc2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:12.514565Z","iopub.execute_input":"2023-12-23T19:58:12.515051Z","iopub.status.idle":"2023-12-23T19:58:12.522175Z","shell.execute_reply.started":"2023-12-23T19:58:12.515003Z","shell.execute_reply":"2023-12-23T19:58:12.520680Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"combined_answers = train_data_analysis['student_answer'].tolist() + train_data_analysis['model_answer'].tolist()\n\n# Tag documents (student and model answers) for Doc2Vec training\ntagged_data = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(combined_answers)\n]\n\n# Train Doc2Vec model\nmax_epochs = 11  # Set the number of epochs for training\nvec_size = 100     # Set the dimensionality of the embeddings\nmodel = Doc2Vec(vector_size=vec_size, epochs=max_epochs)\nmodel.build_vocab(tagged_data)\nmodel.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:12.524647Z","iopub.execute_input":"2023-12-23T19:58:12.525175Z","iopub.status.idle":"2023-12-23T19:58:16.382437Z","shell.execute_reply.started":"2023-12-23T19:58:12.525125Z","shell.execute_reply":"2023-12-23T19:58:16.381510Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"code","source":"# Extract text data from the 'text_column' in new_data\ntext_data = test_data['student_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nstudent_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]\n\ntext_data = test_data['model_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nmodel_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:16.383500Z","iopub.execute_input":"2023-12-23T19:58:16.383807Z","iopub.status.idle":"2023-12-23T19:58:17.089544Z","shell.execute_reply.started":"2023-12-23T19:58:16.383780Z","shell.execute_reply":"2023-12-23T19:58:17.088594Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings,model_embeddings,test_data,\"lose_ends\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:17.091156Z","iopub.execute_input":"2023-12-23T19:58:17.091628Z","iopub.status.idle":"2023-12-23T19:58:17.192018Z","shell.execute_reply.started":"2023-12-23T19:58:17.091585Z","shell.execute_reply":"2023-12-23T19:58:17.190993Z"},"trusted":true},"execution_count":230,"outputs":[{"name":"stdout","text":"54.72222222222223 0.1312117221396637 -1.4666259159478696\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings,model_embeddings,test_data,\"easy\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:17.194351Z","iopub.execute_input":"2023-12-23T19:58:17.194797Z","iopub.status.idle":"2023-12-23T19:58:17.305413Z","shell.execute_reply.started":"2023-12-23T19:58:17.194754Z","shell.execute_reply":"2023-12-23T19:58:17.304189Z"},"trusted":true},"execution_count":231,"outputs":[{"name":"stdout","text":"56.648148148148145 0.13068808597069329 -1.9243211291233377\n","output_type":"stream"}]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings,model_embeddings,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:17.306743Z","iopub.execute_input":"2023-12-23T19:58:17.307143Z","iopub.status.idle":"2023-12-23T19:58:17.411362Z","shell.execute_reply.started":"2023-12-23T19:58:17.307114Z","shell.execute_reply":"2023-12-23T19:58:17.410214Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"59.03703703703703 0.13463079548654686 -1.9934734067061717\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assume train_data_644 is your new dataset\n\n# Combine student and model answers from train_data_644\ncombined_answers_new = train_data_644['student_answer'].tolist() + train_data_644['model_answer'].tolist()\n\n# Tag documents (student and model answers) for Doc2Vec training\ntagged_data_new = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(combined_answers_new, start=len(tagged_data))  # Start indexing from the last index\n]\n\n# Update the existing model with the new tagged data\nmodel.build_vocab(tagged_data_new, update=True)\nmodel.train(tagged_data_new, total_examples=model.corpus_count, epochs=model.epochs)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:17.413388Z","iopub.execute_input":"2023-12-23T19:58:17.413836Z","iopub.status.idle":"2023-12-23T19:58:18.192400Z","shell.execute_reply.started":"2023-12-23T19:58:17.413793Z","shell.execute_reply":"2023-12-23T19:58:18.191439Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"# Extract text data from the 'text_column' in new_data\ntext_data = test_data['student_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nstudent_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]\n\ntext_data = test_data['model_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nmodel_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:18.193751Z","iopub.execute_input":"2023-12-23T19:58:18.194057Z","iopub.status.idle":"2023-12-23T19:58:18.939851Z","shell.execute_reply.started":"2023-12-23T19:58:18.194029Z","shell.execute_reply":"2023-12-23T19:58:18.938868Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings,model_embeddings,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:18.941398Z","iopub.execute_input":"2023-12-23T19:58:18.941728Z","iopub.status.idle":"2023-12-23T19:58:19.043858Z","shell.execute_reply.started":"2023-12-23T19:58:18.941699Z","shell.execute_reply":"2023-12-23T19:58:19.042709Z"},"trusted":true},"execution_count":235,"outputs":[{"name":"stdout","text":"63.96296296296297 0.2752849249436091 -1.4789915257240942\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine student and model answers from train_data_644\ncombined_answers_new2 = train_data_translated['student_answer'].tolist() + train_data_translated['model_answer'].tolist()\n\n# Tag documents (student and model answers) for Doc2Vec training\ntagged_data_new2 = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(combined_answers_new2, start=len(tagged_data_new))  # Start indexing from the last index\n]\n\n# Update the existing model with the new tagged data\nmodel.build_vocab(tagged_data_new2, update=True)\nmodel.train(tagged_data_new2, total_examples=model.corpus_count, epochs=model.epochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:19.045308Z","iopub.execute_input":"2023-12-23T19:58:19.045742Z","iopub.status.idle":"2023-12-23T19:58:23.041445Z","shell.execute_reply.started":"2023-12-23T19:58:19.045710Z","shell.execute_reply":"2023-12-23T19:58:23.040386Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"# Extract text data from the 'text_column' in new_data\ntext_data = test_data['student_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nstudent_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]\n\ntext_data = test_data['model_answer'].tolist()\n\ntagged = [\n    TaggedDocument(words=str(doc).split(), tags=[f'DOC_{idx}'])\n    for idx, doc in enumerate(text_data)\n]\n\n# Infer embeddings using the trained Doc2Vec model\nmodel_embeddings = [\n    model.infer_vector(tagged[idx].words)\n    for idx in range(len(tagged_data_new))\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:23.042820Z","iopub.execute_input":"2023-12-23T19:58:23.043321Z","iopub.status.idle":"2023-12-23T19:58:23.966212Z","shell.execute_reply.started":"2023-12-23T19:58:23.043255Z","shell.execute_reply":"2023-12-23T19:58:23.965286Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings,model_embeddings,test_data,\"fair\")\nprint(precentage,correlation_coefficient,r_squared)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T19:58:23.967508Z","iopub.execute_input":"2023-12-23T19:58:23.968419Z","iopub.status.idle":"2023-12-23T19:58:24.100056Z","shell.execute_reply.started":"2023-12-23T19:58:23.968382Z","shell.execute_reply":"2023-12-23T19:58:24.098973Z"},"trusted":true},"execution_count":238,"outputs":[{"name":"stdout","text":"59.25925925925925 0.24330491904054874 -1.9957518915643742\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"/kaggle/working/knowladge_based\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:07:52.937515Z","iopub.execute_input":"2023-12-23T20:07:52.938021Z","iopub.status.idle":"2023-12-23T20:07:52.958373Z","shell.execute_reply.started":"2023-12-23T20:07:52.937986Z","shell.execute_reply":"2023-12-23T20:07:52.956859Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(embedding_matrix)\n\ndf.to_excel(r\"/kaggle/working/lsa_embedding_matrix.xlsx\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:09:29.792828Z","iopub.execute_input":"2023-12-23T20:09:29.793436Z","iopub.status.idle":"2023-12-23T20:09:30.295671Z","shell.execute_reply.started":"2023-12-23T20:09:29.793381Z","shell.execute_reply":"2023-12-23T20:09:30.294223Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}