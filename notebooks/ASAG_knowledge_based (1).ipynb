{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-23T19:55:53.302349Z",
     "iopub.status.busy": "2023-12-23T19:55:53.301828Z",
     "iopub.status.idle": "2023-12-23T19:55:53.313597Z",
     "shell.execute_reply": "2023-12-23T19:55:53.312303Z",
     "shell.execute_reply.started": "2023-12-23T19:55:53.302308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/auto-grading-data/Traing_Data_analysis.xlsx\n",
      "/kaggle/input/auto-grading-data/Traing_Data_614.xlsx\n",
      "/kaggle/input/auto-grading-data/Traing_Data_translated.xlsx\n",
      "/kaggle/input/auto-grading-data/Test_Dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:55:53.317507Z",
     "iopub.status.busy": "2023-12-23T19:55:53.316570Z",
     "iopub.status.idle": "2023-12-23T19:56:37.004532Z",
     "shell.execute_reply": "2023-12-23T19:56:37.003065Z",
     "shell.execute_reply.started": "2023-12-23T19:55:53.317454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (68.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1+cpu)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-md==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy  \n",
    "!pip install -U sentence-transformers\n",
    "!python -m spacy download en_core_web_md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import torch\n",
    "import spacy\n",
    "import fasttext.util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:56:37.009172Z",
     "iopub.status.busy": "2023-12-23T19:56:37.008086Z",
     "iopub.status.idle": "2023-12-23T19:56:37.881774Z",
     "shell.execute_reply": "2023-12-23T19:56:37.880226Z",
     "shell.execute_reply.started": "2023-12-23T19:56:37.009114Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(\"/kaggle/input/auto-grading-data/Test_Dataset.xlsx\")\n",
    "train_data_644= pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_614.xlsx\")\n",
    "train_data_analysis = pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_analysis.xlsx\")\n",
    "train_data_translated = pd.read_excel(\"/kaggle/input/auto-grading-data/Traing_Data_translated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:56:37.883836Z",
     "iopub.status.busy": "2023-12-23T19:56:37.883497Z",
     "iopub.status.idle": "2023-12-23T19:57:40.348182Z",
     "shell.execute_reply": "2023-12-23T19:57:40.346926Z",
     "shell.execute_reply.started": "2023-12-23T19:56:37.883806Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "# Load Word2Vec model (pre-trained model available in gensim)\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:40.351301Z",
     "iopub.status.busy": "2023-12-23T19:57:40.350802Z",
     "iopub.status.idle": "2023-12-23T19:57:42.861755Z",
     "shell.execute_reply": "2023-12-23T19:57:42.860365Z",
     "shell.execute_reply.started": "2023-12-23T19:57:40.351251Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load spaCy with GloVe vectors\n",
    "nlp = spacy.load(\"en_core_web_md\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.863601Z",
     "iopub.status.busy": "2023-12-23T19:57:42.863205Z",
     "iopub.status.idle": "2023-12-23T19:57:42.871354Z",
     "shell.execute_reply": "2023-12-23T19:57:42.870036Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.863566Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model, text):\n",
    "    words = text.split()  # Split the text into individual words\n",
    "    word_embeddings = []\n",
    "    for word in words:\n",
    "        if word in model:  # Check if the word is in the Word2Vec vocabulary\n",
    "            word_embeddings.append(model[word])  # Retrieve the word embedding\n",
    "        else:\n",
    "            # Handle out-of-vocabulary words if needed\n",
    "            pass  # For example, you might skip the word or use a default embedding\n",
    "    \n",
    "    if word_embeddings:\n",
    "        # Calculate the average of word embeddings or apply other aggregation methods\n",
    "        sentence_embedding = np.mean(word_embeddings, axis=0)  # Calculate the mean along the axis\n",
    "\n",
    "        return sentence_embedding  # Return the sentence-level embedding\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no embeddings were found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.873120Z",
     "iopub.status.busy": "2023-12-23T19:57:42.872755Z",
     "iopub.status.idle": "2023-12-23T19:57:42.885352Z",
     "shell.execute_reply": "2023-12-23T19:57:42.884152Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.873088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['question', 'model_answer', 'student_answer', 'grade', 'source', 'ID'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.887664Z",
     "iopub.status.busy": "2023-12-23T19:57:42.887296Z",
     "iopub.status.idle": "2023-12-23T19:57:42.903849Z",
     "shell.execute_reply": "2023-12-23T19:57:42.902636Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.887631Z"
    }
   },
   "outputs": [],
   "source": [
    "def Gradanizer(num, grade_mode=\"Fair\"):\n",
    "    \"\"\"\n",
    "    This function take the garde form 0 to 1 and output that garde in form 0 to 5\n",
    "\n",
    "    parameters\n",
    "    num: the garde in form 0 to 1\n",
    "    grade_mode: how fair you want to model to be [fair: the exact transformation with out any lose ranges, easy: more skewed into higher grades more \n",
    "    common, lose_ends: more skewed into higher grades and lower grades]\n",
    "    \"\"\"\n",
    "    def get_region_value_f(number):    \n",
    "        intervals = [\n",
    "        (-10, 0.4545), (0.4545, 0.9091), (0.9091, 1.3636),\n",
    "        (1.3636, 1.8182), (1.8182, 2.2727), (2.2727, 2.7273),\n",
    "        (2.7273, 3.1818), (3.1818, 3.6364), (3.6364, 4.0909),\n",
    "        (4.0909, 4.5455), (4.5455, 6)]\n",
    "        values=[0,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5]\n",
    "        for i, (start, end) in enumerate(intervals):\n",
    "            if start <= number < end:\n",
    "                return values[i]\n",
    "        \n",
    "    def get_region_value_e(number):    \n",
    "        intervals = [\n",
    "        (-10, 0.4545), (0.4545, 0.9091), (0.9091, 1.3636),\n",
    "        (1.3636, 1.8182), (1.8182, 2.2727), (2.2727, 2.7273),\n",
    "        (2.7273, 3.1818), (3.1818, 3.6364)]\n",
    "        values=[0,0.5,1,1.5,2,2.5,3,3.5]\n",
    "        for i, (start, end) in enumerate(intervals):\n",
    "            if start <= number < end:\n",
    "                return values[i]\n",
    "    def get_region_value_l(number):    \n",
    "        intervals = [\n",
    "        (1.0000, 1.3571), (1.3571, 1.7143), (1.7143, 2.0714),\n",
    "        (2.0714, 2.4286), (2.4286, 2.7857), (2.7857, 3.1429),\n",
    "        (3.1429, 3.5000)]\n",
    "        values=[0.5,1,1.5,2,2.5,3,3.5]\n",
    "        for i, (start, end) in enumerate(intervals):\n",
    "            if start <= number < end:\n",
    "                return values[i]\n",
    "\n",
    "    if (grade_mode == \"fair\"):\n",
    "        num_f=num*5\n",
    "        return get_region_value_f(num_f)\n",
    "    elif (grade_mode == \"easy\"):\n",
    "        if (num >=0.85):\n",
    "            return 5\n",
    "        elif ( 0.85>num>=0.8):\n",
    "            return 4.5\n",
    "        elif ( 0.8>num>=0.7):\n",
    "            return 4\n",
    "        else:\n",
    "            num_e = num*5\n",
    "            return get_region_value_e(num_e)\n",
    "    elif (grade_mode == \"lose_ends\"):\n",
    "        if (num >=0.85):\n",
    "            return 5\n",
    "        elif ( 0.85>num>=0.8):\n",
    "            return 4.5\n",
    "        elif ( 0.8>num>=0.7):\n",
    "            return 4\n",
    "        elif (0.2>=num):\n",
    "            return 0\n",
    "        else:\n",
    "            num_l = num*5\n",
    "            return get_region_value_l(num_l)\n",
    "    else:\n",
    "        print(\"not a valid mode \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.906326Z",
     "iopub.status.busy": "2023-12-23T19:57:42.905783Z",
     "iopub.status.idle": "2023-12-23T19:57:42.920359Z",
     "shell.execute_reply": "2023-12-23T19:57:42.919081Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.906253Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.922894Z",
     "iopub.status.busy": "2023-12-23T19:57:42.922341Z",
     "iopub.status.idle": "2023-12-23T19:57:42.932030Z",
     "shell.execute_reply": "2023-12-23T19:57:42.930980Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.922848Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.937967Z",
     "iopub.status.busy": "2023-12-23T19:57:42.937558Z",
     "iopub.status.idle": "2023-12-23T19:57:42.949592Z",
     "shell.execute_reply": "2023-12-23T19:57:42.948048Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.937932Z"
    }
   },
   "outputs": [],
   "source": [
    "def Evaluation(embeddings_1=None, embeddings_2=None,test_data=None,mode=\"easy\"):\n",
    "    \"\"\"\n",
    "    this function takes two lists of embeddings in the form of torch tensor or list or df column one for the student answer and other for model answer\n",
    "    or any two sentences if this function used in any other code and the test data frame and the mode of Gradazier and output MAE % and r_squared and \n",
    "    correlation_coefficient\n",
    "\n",
    "    parameters\n",
    "    embeddings_1:list or tensor or df column that hold the sentence embeddings (student answer embeddings)\n",
    "    embeddings_2:list or tensor or df column that hold the sentence embeddings (model answer embeddings)\n",
    "    data: the test data frame\n",
    "    mode: the mode of which gradazier is used [\"fair\", \"easy\", \"lose_ends\"]\n",
    "    \"\"\"\n",
    "    from sentence_transformers import util\n",
    "    if (len(embeddings_1) != len(embeddings_2)):\n",
    "        print(\"embeddings_1 and embeddings_2 are not the same length\")\n",
    "        return None\n",
    "    elif (mode not in [\"easy\",\"lose_ends\",\"fair\"]):\n",
    "        print(\"not valid mode\")\n",
    "        return None\n",
    "    else:\n",
    "        predicted = []\n",
    "        for i in range(len(embeddings_1)):\n",
    "            predicted.append(Gradanizer(util.cos_sim(embeddings_1[i], embeddings_2[i]),mode))\n",
    "        transformed_grade=[]\n",
    "        for i in range(len(embeddings_1)):\n",
    "            transformed_grade.append(Gradanizer(test_data[\"grade\"][i],mode))\n",
    "            #transformed_grade.append(test_data[\"grade\"][i]*5)\n",
    "        arr_predicted =np.array(predicted)\n",
    "        arr_grade=np.array(transformed_grade)\n",
    "        MAE = (1-((np.sum(np.abs(arr_predicted-arr_grade))/len(embeddings_1))/5))*100\n",
    "        correlation_coefficient, p_value = spearmanr(arr_grade, arr_predicted)\n",
    "        r_squared = r2_score(arr_grade, arr_predicted)\n",
    "        dif =arr_predicted-arr_grade\n",
    "        hits_precentage= (np.count_nonzero(dif == 0)/len(embeddings_1))\n",
    "        return MAE,correlation_coefficient,r_squared\n",
    "        #if you want the hit precentage tag the above and untag the blew\n",
    "        #return MAE,correlation_coefficient,hits_precentage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:42.951326Z",
     "iopub.status.busy": "2023-12-23T19:57:42.950959Z",
     "iopub.status.idle": "2023-12-23T19:57:43.128172Z",
     "shell.execute_reply": "2023-12-23T19:57:43.126766Z",
     "shell.execute_reply.started": "2023-12-23T19:57:42.951290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get embeddings for train and test data using different models\n",
    "train_word2vec = test_data['student_answer'].apply(lambda x: get_embeddings(word2vec_model, x))\n",
    "test_word2vec = test_data['model_answer'].apply(lambda x: get_embeddings(word2vec_model, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.130142Z",
     "iopub.status.busy": "2023-12-23T19:57:43.129770Z",
     "iopub.status.idle": "2023-12-23T19:57:43.144340Z",
     "shell.execute_reply": "2023-12-23T19:57:43.142941Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.130109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.038584497, -0.017718472, 0.053652238, 0.100...\n",
       "1    [-0.0021623883, -0.0023314613, 0.052162714, 0....\n",
       "2    [0.013964201, 0.008574185, 0.01831376, 0.06740...\n",
       "3    [-0.009379069, 0.008200905, 0.059607305, 0.096...\n",
       "4    [0.029686783, -0.0011798522, 0.0065001543, 0.0...\n",
       "Name: student_answer, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word2vec[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.146501Z",
     "iopub.status.busy": "2023-12-23T19:57:43.146097Z",
     "iopub.status.idle": "2023-12-23T19:57:43.213886Z",
     "shell.execute_reply": "2023-12-23T19:57:43.212565Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.146464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0386, -0.0177,  0.0537,  ..., -0.0176,  0.0411,  0.0087],\n",
       "        [-0.0022, -0.0023,  0.0522,  ..., -0.0582,  0.0067,  0.0026],\n",
       "        [ 0.0140,  0.0086,  0.0183,  ..., -0.0259, -0.0333,  0.0174],\n",
       "        [-0.0094,  0.0082,  0.0596,  ..., -0.0354,  0.0174, -0.0468],\n",
       "        [ 0.0297, -0.0012,  0.0065,  ..., -0.0396,  0.0045, -0.0050]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_word2vec= torch.tensor(train_word2vec)\n",
    "train_word2vec[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.217168Z",
     "iopub.status.busy": "2023-12-23T19:57:43.216778Z",
     "iopub.status.idle": "2023-12-23T19:57:43.279800Z",
     "shell.execute_reply": "2023-12-23T19:57:43.278347Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.217130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0603, -0.0067,  0.0547,  ..., -0.0294,  0.0533, -0.0027],\n",
       "        [-0.0121, -0.0123,  0.0270,  ..., -0.0526, -0.0025,  0.0232],\n",
       "        [ 0.0164,  0.0048, -0.0057,  ..., -0.0028,  0.0467, -0.0071],\n",
       "        [ 0.0603, -0.0067,  0.0547,  ..., -0.0294,  0.0533, -0.0027],\n",
       "        [-0.0091,  0.0118,  0.0255,  ..., -0.0364, -0.0146, -0.0007]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word2vec= torch.tensor(test_word2vec)\n",
    "test_word2vec[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.282137Z",
     "iopub.status.busy": "2023-12-23T19:57:43.281755Z",
     "iopub.status.idle": "2023-12-23T19:57:43.458797Z",
     "shell.execute_reply": "2023-12-23T19:57:43.457355Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.282104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.67338282078472 0.20310990847400123 -0.2531905664319225\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"fair\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.460681Z",
     "iopub.status.busy": "2023-12-23T19:57:43.460328Z",
     "iopub.status.idle": "2023-12-23T19:57:43.590066Z",
     "shell.execute_reply": "2023-12-23T19:57:43.588626Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.460651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.60233297985154 0.21395528365860808 -0.26623965555920215\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"easy\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.591998Z",
     "iopub.status.busy": "2023-12-23T19:57:43.591527Z",
     "iopub.status.idle": "2023-12-23T19:57:43.725508Z",
     "shell.execute_reply": "2023-12-23T19:57:43.723399Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.591961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.89819724284199 0.2121318116148784 -0.24400963653160956\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_word2vec,test_word2vec,test_data,\"lose_ends\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:57:43.727897Z",
     "iopub.status.busy": "2023-12-23T19:57:43.727409Z",
     "iopub.status.idle": "2023-12-23T19:58:11.018560Z",
     "shell.execute_reply": "2023-12-23T19:58:11.016194Z",
     "shell.execute_reply.started": "2023-12-23T19:57:43.727856Z"
    }
   },
   "outputs": [],
   "source": [
    "train_glove = np.array([nlp(text).vector for text in test_data['student_answer']])\n",
    "test_glove = np.array([nlp(text).vector for text in test_data['model_answer']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.023088Z",
     "iopub.status.busy": "2023-12-23T19:58:11.021438Z",
     "iopub.status.idle": "2023-12-23T19:58:11.030874Z",
     "shell.execute_reply": "2023-12-23T19:58:11.029656Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.023028Z"
    }
   },
   "outputs": [],
   "source": [
    "train_glove= torch.tensor(train_glove)\n",
    "test_glove= torch.tensor(test_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.033609Z",
     "iopub.status.busy": "2023-12-23T19:58:11.032481Z",
     "iopub.status.idle": "2023-12-23T19:58:11.274176Z",
     "shell.execute_reply": "2023-12-23T19:58:11.273185Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.033568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.42523860021208 0.06520601135437996 -0.5530007747644257\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"fair\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.276179Z",
     "iopub.status.busy": "2023-12-23T19:58:11.275399Z",
     "iopub.status.idle": "2023-12-23T19:58:11.401870Z",
     "shell.execute_reply": "2023-12-23T19:58:11.399860Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.276143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.90243902439025 0.04361425359018988 -0.5487960826142768\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"easy\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.404204Z",
     "iopub.status.busy": "2023-12-23T19:58:11.403787Z",
     "iopub.status.idle": "2023-12-23T19:58:11.520972Z",
     "shell.execute_reply": "2023-12-23T19:58:11.520095Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.404167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.62248144220572 0.0418207984264587 -0.5161487988798423\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(train_glove,test_glove,test_data,\"lose_ends\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.522949Z",
     "iopub.status.busy": "2023-12-23T19:58:11.522408Z",
     "iopub.status.idle": "2023-12-23T19:58:11.528112Z",
     "shell.execute_reply": "2023-12-23T19:58:11.526548Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.522916Z"
    }
   },
   "outputs": [],
   "source": [
    "#fasttext.util.download_model('en', if_exists='ignore')  # Uncomment if you want to download the FastText model\n",
    "#fasttext_model = fasttext.load_model('cc.en.300.bin')  # Load your FastText model (change the path if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.530812Z",
     "iopub.status.busy": "2023-12-23T19:58:11.530157Z",
     "iopub.status.idle": "2023-12-23T19:58:11.539863Z",
     "shell.execute_reply": "2023-12-23T19:58:11.538395Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.530762Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#train_fasttext = np.array([fasttext_model.get_sentence_vector(text) for text in test_data['student_answer']])\n",
    "#test_fasttext = np.array([fasttext_model.get_sentence_vector(text) for text in test_data['model_answer']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.542118Z",
     "iopub.status.busy": "2023-12-23T19:58:11.541735Z",
     "iopub.status.idle": "2023-12-23T19:58:11.551956Z",
     "shell.execute_reply": "2023-12-23T19:58:11.550348Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.542069Z"
    }
   },
   "outputs": [],
   "source": [
    "#test_fasttext= torch.tensor(test_fasttext)\n",
    "#train_fasttext= torch.tensor(train_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.554095Z",
     "iopub.status.busy": "2023-12-23T19:58:11.553718Z",
     "iopub.status.idle": "2023-12-23T19:58:11.563011Z",
     "shell.execute_reply": "2023-12-23T19:58:11.561649Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.554062Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install conceptnet\n",
    "\n",
    "#from conceptnet.nodes import standardized_concept_uri\n",
    "#from conceptnet.vectors.query import VectorSpaceWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T19:58:11.585869Z",
     "iopub.status.busy": "2023-12-23T19:58:11.584689Z",
     "iopub.status.idle": "2023-12-23T19:58:11.726606Z",
     "shell.execute_reply": "2023-12-23T19:58:11.725380Z",
     "shell.execute_reply.started": "2023-12-23T19:58:11.585758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the initial LSA model on the first dataset\n",
    "initial_text_data = train_data_analysis['student_answer'].tolist() + train_data_analysis['model_answer'].tolist()\n",
    "initial_tfidf_matrix = TfidfVectorizer().fit_transform(initial_text_data)\n",
    "initial_lsa_model = TruncatedSVD(n_components=11).fit(initial_tfidf_matrix)\n",
    "\n",
    "# Store the initial LSA model and TF-IDF matrix\n",
    "overall_embedding_matrix = initial_lsa_model.transform(initial_tfidf_matrix)\n",
    "overall_tfidf_matrix = initial_tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:29.995614Z",
     "iopub.status.busy": "2023-12-23T20:01:29.994849Z",
     "iopub.status.idle": "2023-12-23T20:01:30.126689Z",
     "shell.execute_reply": "2023-12-23T20:01:30.125333Z",
     "shell.execute_reply.started": "2023-12-23T20:01:29.995574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers = train_data_analysis['student_answer'].tolist() + train_data_analysis['model_answer'].tolist()\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(all_answers)\n",
    "\n",
    "# Perform Singular Value Decomposition (LSA)\n",
    "num_dimensions = 11  # Choose the number of dimensions for the embeddings\n",
    "lsa = TruncatedSVD(n_components=num_dimensions)\n",
    "embedding_matrix = lsa.fit_transform(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:33.894910Z",
     "iopub.status.busy": "2023-12-23T20:01:33.894463Z",
     "iopub.status.idle": "2023-12-23T20:01:33.952802Z",
     "shell.execute_reply": "2023-12-23T20:01:33.951608Z",
     "shell.execute_reply.started": "2023-12-23T20:01:33.894875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n",
    "\n",
    "tfidf_matrix = vectorizer.transform(all_answers2)\n",
    "\n",
    "embedding_matrix = lsa.transform(tfidf_matrix)\n",
    "\n",
    "# Separate embeddings for student and model answers\n",
    "student_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\n",
    "model_embeddings2 = embedding_matrix[len(test_data['student_answer']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:35.124524Z",
     "iopub.status.busy": "2023-12-23T20:01:35.124085Z",
     "iopub.status.idle": "2023-12-23T20:01:35.341950Z",
     "shell.execute_reply": "2023-12-23T20:01:35.340804Z",
     "shell.execute_reply.started": "2023-12-23T20:01:35.124487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.95440084835631 0.09677187203405786 -1.05425016067396\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:36.405068Z",
     "iopub.status.busy": "2023-12-23T20:01:36.404566Z",
     "iopub.status.idle": "2023-12-23T20:01:36.510837Z",
     "shell.execute_reply": "2023-12-23T20:01:36.509583Z",
     "shell.execute_reply.started": "2023-12-23T20:01:36.405025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.71155885471899 0.09314136286388634 -0.7897280793406143\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"easy\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:37.596721Z",
     "iopub.status.busy": "2023-12-23T20:01:37.596254Z",
     "iopub.status.idle": "2023-12-23T20:01:37.695102Z",
     "shell.execute_reply": "2023-12-23T20:01:37.693917Z",
     "shell.execute_reply.started": "2023-12-23T20:01:37.596683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.5694591728526 0.09011019129467626 -0.7251231308460437\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"lose_ends\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:01:52.169927Z",
     "iopub.status.busy": "2023-12-23T20:01:52.169520Z",
     "iopub.status.idle": "2023-12-23T20:01:52.237133Z",
     "shell.execute_reply": "2023-12-23T20:01:52.235577Z",
     "shell.execute_reply.started": "2023-12-23T20:01:52.169894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers = train_data_644['student_answer'].tolist() + train_data_644['model_answer'].tolist()\n",
    "\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(all_answers)\n",
    "\n",
    "embedding_matrix = lsa.fit(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:02:05.367699Z",
     "iopub.status.busy": "2023-12-23T20:02:05.367224Z",
     "iopub.status.idle": "2023-12-23T20:02:05.421104Z",
     "shell.execute_reply": "2023-12-23T20:02:05.419919Z",
     "shell.execute_reply.started": "2023-12-23T20:02:05.367659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n",
    "\n",
    "tfidf_matrix = vectorizer.transform(all_answers2)\n",
    "\n",
    "embedding_matrix = lsa.transform(tfidf_matrix)\n",
    "\n",
    "# Separate embeddings for student and model answers\n",
    "student_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\n",
    "model_embeddings2 = embedding_matrix[len(test_data['student_answer']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:02:18.610450Z",
     "iopub.status.busy": "2023-12-23T20:02:18.609740Z",
     "iopub.status.idle": "2023-12-23T20:02:18.830658Z",
     "shell.execute_reply": "2023-12-23T20:02:18.829477Z",
     "shell.execute_reply.started": "2023-12-23T20:02:18.610409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.53022269353129 0.07340128025859846 -1.1079314871435217\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:02:49.367706Z",
     "iopub.status.busy": "2023-12-23T20:02:49.366936Z",
     "iopub.status.idle": "2023-12-23T20:02:49.534620Z",
     "shell.execute_reply": "2023-12-23T20:02:49.533427Z",
     "shell.execute_reply.started": "2023-12-23T20:02:49.367662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers = train_data_translated['student_answer'].tolist() + train_data_translated['model_answer'].tolist()\n",
    "\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(all_answers)\n",
    "\n",
    "embedding_matrix = lsa.fit(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:03:16.757538Z",
     "iopub.status.busy": "2023-12-23T20:03:16.756953Z",
     "iopub.status.idle": "2023-12-23T20:03:16.811363Z",
     "shell.execute_reply": "2023-12-23T20:03:16.810275Z",
     "shell.execute_reply.started": "2023-12-23T20:03:16.757480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine student and model answers\n",
    "all_answers2 = test_data['student_answer'].tolist() + test_data['model_answer'].tolist()\n",
    "\n",
    "tfidf_matrix = vectorizer.transform(all_answers2)\n",
    "\n",
    "embedding_matrix = lsa.transform(tfidf_matrix)\n",
    "\n",
    "# Separate embeddings for student and model answers\n",
    "student_embeddings2 = embedding_matrix[:len(test_data['student_answer'])]\n",
    "model_embeddings2 = embedding_matrix[len(test_data['student_answer']):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T20:03:25.791112Z",
     "iopub.status.busy": "2023-12-23T20:03:25.790208Z",
     "iopub.status.idle": "2023-12-23T20:03:26.065493Z",
     "shell.execute_reply": "2023-12-23T20:03:26.064330Z",
     "shell.execute_reply.started": "2023-12-23T20:03:25.791059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.6574761399788 0.01756348328179278 -1.0918270892026531\n"
     ]
    }
   ],
   "source": [
    "precentage,correlation_coefficient,r_squared = Evaluation(student_embeddings2,student_embeddings2,test_data,\"fair\")\n",
    "print(precentage,correlation_coefficient,r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4208408,
     "sourceId": 7261471,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
